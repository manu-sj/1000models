{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecasting Model Training Pipeline\n",
    "\n",
    "This notebook trains demand forecasting models for each item-location combination using the feature store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import hopsworks\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "Set the parameters for the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure training parameters\n",
    "project_name = 'many_models'\n",
    "feature_group_name = 'demand_features'\n",
    "version = 1  # Version can be incremented automatically \n",
    "model_name = 'demand_forecaster'\n",
    "# model_version = 1  # Let Hopsworks handle versioning automatically\n",
    "test_size = 0.2\n",
    "location_id = None  # Set to specific location ID to filter for a single location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks\n",
    "\n",
    "Establish connection to the Hopsworks Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Hopsworks\n",
      "2025-05-09 10:17:10,552 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-09 10:17:10,558 INFO: Initializing external client\n",
      "2025-05-09 10:17:10,559 INFO: Base URL: https://10.87.43.175:28181\n",
      "2025-05-09 10:17:12,194 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://10.87.43.175:28181/p/123\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to Hopsworks\")\n",
    "# Connect to Hopsworks\n",
    "project = hopsworks.login(project=\"test2\"\n",
    ")\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Feature Group\n",
    "\n",
    "Get the feature group containing the demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Feature Group: demand_features\n",
      "Feature Group Investigation\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.40s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_id</th>\n",
       "      <th>loc_id</th>\n",
       "      <th>time_bucket</th>\n",
       "      <th>repetitive_demand_quantity</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046137</td>\n",
       "      <td>3</td>\n",
       "      <td>202412</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-05-09 10:14:27.519113+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10012177</td>\n",
       "      <td>3</td>\n",
       "      <td>202209</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2025-05-09 10:14:27.519113+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8911185</td>\n",
       "      <td>3</td>\n",
       "      <td>202112</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2025-05-09 10:14:27.519113+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8400517</td>\n",
       "      <td>3</td>\n",
       "      <td>202407</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2025-05-09 10:14:27.519113+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9033029</td>\n",
       "      <td>3</td>\n",
       "      <td>202203</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-05-09 10:14:27.519113+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sp_id  loc_id  time_bucket  repetitive_demand_quantity  \\\n",
       "0   9046137       3       202412                         3.0   \n",
       "1  10012177       3       202209                        28.0   \n",
       "2   8911185       3       202112                        99.0   \n",
       "3   8400517       3       202407                        16.0   \n",
       "4   9033029       3       202203                         8.0   \n",
       "\n",
       "                          datetime  \n",
       "0 2025-05-09 10:14:27.519113+00:00  \n",
       "1 2025-05-09 10:14:27.519113+00:00  \n",
       "2 2025-05-09 10:14:27.519113+00:00  \n",
       "3 2025-05-09 10:14:27.519113+00:00  \n",
       "4 2025-05-09 10:14:27.519113+00:00  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Retrieving Feature Group: {feature_group_name}\")\n",
    "demand_fg = fs.get_feature_group(\n",
    "    name=feature_group_name,\n",
    "#    version=1,  # Using fixed version if needed\n",
    ")\n",
    "\n",
    "print(\"Feature Group Investigation\")\n",
    "demand_fg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Query\n",
    "\n",
    "Select features and prepare the query for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Selection\")\n",
    "# Define query with proper feature selection\n",
    "query = demand_fg.select_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Transformation Functions\n",
    "\n",
    "Define transformation functions for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up transformation functions\n",
      "Applying label encoding to location ID\n",
      "Created transformation function for repetitive_demand_quantity using min_max_scaler\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up transformation functions\")\n",
    "# Import the built-in transformations\n",
    "from hopsworks.hsfs.builtin_transformations import min_max_scaler\n",
    "\n",
    "print(\"Applying label encoding to location ID\")\n",
    "transformation_functions = [min_max_scaler(\"repetitive_demand_quantity\")]\n",
    "\n",
    "print(\"Created transformation function for repetitive_demand_quantity using min_max_scaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature View\n",
    "\n",
    "Create a feature view for the demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting or creating feature view: demand_features_view\n",
      "Feature view created successfully, explore it at \n",
      "https://10.87.43.175:28181/p/123/fs/71/fv/demand_features_view/version/1\n",
      "Successfully got or created feature view: demand_features_view\n"
     ]
    }
   ],
   "source": [
    "print(f\"Getting or creating feature view: {feature_group_name}_view\")\n",
    "\n",
    "# Use get_or_create_feature_view method\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=f\"{feature_group_name}_view\",\n",
    "    version=1,  \n",
    "    description=\"Feature view for demand forecasting\",\n",
    "    labels=[\"repetitive_demand_quantity\"],\n",
    "    query=query,\n",
    "    transformation_functions=transformation_functions\n",
    ")\n",
    "\n",
    "print(f\"Successfully got or created feature view: {feature_group_name}_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Training Scope\n",
    "\n",
    "Determine the number of models to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.37s) \n",
      "Training 200 models (items: 200 × locations: 1)\n",
      "\n",
      "Data Overview:\n",
      "Unique items: 200\n",
      "Unique locations: 1\n"
     ]
    }
   ],
   "source": [
    "# Get model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Get unique items and locations for training\n",
    "# Read the data once and reuse it\n",
    "df = query.read()\n",
    "items = df['sp_id'].unique()  # Get unique items\n",
    "locations = df['loc_id'].unique() if location_id is None else [location_id]\n",
    "\n",
    "# Calculate total number of models\n",
    "total_models = len(items) * len(locations)\n",
    "\n",
    "print(f\"Training {total_models} models (items: {len(items)} × locations: {len(locations)})\")\n",
    "\n",
    "print(f\"\\nData Overview:\")\n",
    "print(f\"Unique items: {len(items)}\")\n",
    "print(f\"Unique locations: {len(locations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Loop\n",
    "\n",
    "Train models for each item-location combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/200 (Item: 9046137, Location: 3)\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.38s) \n",
      "  RandomForest: RMSE: 0.05\n",
      "  XGBoost: RMSE: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f201353b60f46e093a4f31f7533f3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe56bf3fb58f4e3581296b9e738e354f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item9046137_loc3/model.js…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c94c624c7f44ff8ec56d961eb0ebcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1a5f418605417fa2612fcfa3ef5e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://10.87.43.175:28181/p/123/models/demand_forecaster_item9046137_loc3/1\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (9.36s) \n",
      "2025-05-09 10:18:01,993 INFO: Provenance cached data - overwriting last accessed/created training dataset from 1 to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec9aaa6929646c0aff6a67bd78d0a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9c5447790b4267a7d97b09474f69ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item10012177_loc3/model.j…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df1e78e4d9243f29650c50735965d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d241b69ffcc4a63aee8876ea793d45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://10.87.43.175:28181/p/123/models/demand_forecaster_item10012177_loc3/1\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.99s) \n",
      "2025-05-09 10:18:22,282 INFO: Provenance cached data - overwriting last accessed/created training dataset from 2 to 3.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9413a68ae5c4186854c829d6fda3e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a87d5fb1154740a27e56b9edeadad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item8911185_loc3/model.js…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77906a17440d4c9b8e6af6ef6b869e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83535bd2577d48aabaacd77ce1f09e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://10.87.43.175:28181/p/123/models/demand_forecaster_item8911185_loc3/1\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (7.92s) \n",
      "2025-05-09 10:18:48,460 INFO: Provenance cached data - overwriting last accessed/created training dataset from 3 to 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa84bf0044d6490e9d836fa715fd05ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420eb6c7049545c28759b0a2a0333785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item8400517_loc3/model.js…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e9b92c78bd4d3e97c7334478718b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d6a6d17db04b78abcbefc115f1d972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://10.87.43.175:28181/p/123/models/demand_forecaster_item8400517_loc3/1\n",
      "Training model 5/200 (Item: 9033029, Location: 3)\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (6.23s) \n",
      "2025-05-09 10:19:13,172 INFO: Provenance cached data - overwriting last accessed/created training dataset from 4 to 5.\n",
      "  RandomForest: RMSE: 0.05\n",
      "  XGBoost: RMSE: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a2f7601d584f669733792a1d8defc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e13d4de1dc496ba01d51be41a61faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item9033029_loc3/model.js…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd5574478d2487e9a90f4add63288df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7593de88efd47b7aaa19f7c5c953187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://10.87.43.175:28181/p/123/models/demand_forecaster_item9033029_loc3/1\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.13s) \n",
      "2025-05-09 10:19:34,332 INFO: Provenance cached data - overwriting last accessed/created training dataset from 5 to 6.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5d4628d067451e9136a20c83f68fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dea20fa66842528bd40128a390362b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item8236199_loc3/model.js…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178af9ea6382498899058367f552e760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb39051f5a194caeb9a65dd8172a4fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://10.87.43.175:28181/p/123/models/demand_forecaster_item8236199_loc3/1\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (8.30s) \n",
      "2025-05-09 10:20:01,188 INFO: Provenance cached data - overwriting last accessed/created training dataset from 6 to 7.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2bcc5f217d43f7be3890d8c731e349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6de9f38f21242d999b3cada8158ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/demand_forecaster_item9039502_loc3/model.js…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f918db49404abf8780b12b4a483188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/input_example.json: 0.000%|          | 0/23…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadebd5459ce448091217aaf401ce1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/manu/Desktop/Projects/random/1000models/notebooks/model_schema.json: 0.000%|          | 0/498…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dictionary to store metrics for all models\n",
    "all_model_metrics = {}\n",
    "\n",
    "# Counter for progress tracking\n",
    "model_counter = 0\n",
    "\n",
    "# Loop through each item-location combination\n",
    "for item in items:\n",
    "    for loc in locations:\n",
    "        model_counter += 1\n",
    "        \n",
    "        # Display progress periodically\n",
    "        if model_counter % 5 == 0 or model_counter == 1:\n",
    "            print(f\"Training model {model_counter}/{total_models} (Item: {item}, Location: {loc})\")\n",
    "        \n",
    "        try:\n",
    "            # Create a filter for this item-location combination\n",
    "            from hsfs.constructor.filter import Filter\n",
    "            \n",
    "            # Create filter using feature group \n",
    "            filter_cond = (demand_fg.sp_id == item) and (demand_fg.loc_id == loc)\n",
    "            \n",
    "            # Apply train_test_split with extra_filter\n",
    "            X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "                test_size=test_size,\n",
    "                extra_filter=filter_cond,\n",
    "                )\n",
    "                        \n",
    "            # Skip if we don't have enough data for this combination\n",
    "            if len(X_train) < 10 or len(X_test) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Remove ID columns\n",
    "            X_train = X_train.drop(['sp_id', 'loc_id', 'datetime'], axis=1, errors='ignore')\n",
    "            X_test = X_test.drop(['sp_id', 'loc_id', 'datetime'], axis=1, errors='ignore')\n",
    "            \n",
    "            # Model name for this item-location\n",
    "            model_prefix = f\"{model_name}_item{item}_loc{loc}\"\n",
    "            \n",
    "            # Train RandomForest\n",
    "            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Train XGBoost\n",
    "            xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate models\n",
    "            models = {\n",
    "                \"RandomForest\": rf_model,\n",
    "                \"XGBoost\": xgb_model\n",
    "            }\n",
    "            \n",
    "            best_model = None\n",
    "            best_rmse = float('inf')\n",
    "            best_metrics = {}\n",
    "            \n",
    "            for model_type, model in models.items():\n",
    "                # Make predictions\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "                \n",
    "                metrics = {\n",
    "                    \"mae\": mae,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2\n",
    "                }\n",
    "                \n",
    "                if model_counter % 5 == 0 or model_counter == 1:\n",
    "                    print(f\"  {model_type}: RMSE: {rmse:.2f}\")\n",
    "                \n",
    "                # Track best model\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_model = model\n",
    "                    best_model_type = model_type\n",
    "                    best_metrics = metrics\n",
    "            \n",
    "            # Store metrics for this item-location combination\n",
    "            all_model_metrics[f\"item_{item}_loc_{loc}\"] = {\n",
    "                \"model_type\": best_model_type,\n",
    "                \"metrics\": best_metrics\n",
    "            }\n",
    "            \n",
    "            # Create model directory\n",
    "            model_dir = model_prefix\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Save model\n",
    "            if best_model_type == \"RandomForest\":\n",
    "                joblib.dump(best_model, os.path.join(model_dir, \"model.joblib\"))\n",
    "            else:  # XGBoost\n",
    "                best_model.save_model(os.path.join(model_dir, \"model.json\"))\n",
    "            \n",
    "            # Register model in Hopsworks\n",
    "            model_api = mr.python.create_model(\n",
    "                name=model_prefix,\n",
    "                metrics=best_metrics,\n",
    "                description=f\"Demand forecaster for item {item}, location {loc}\",\n",
    "                input_example=X_train.iloc[0].to_dict() if not X_train.empty else None,\n",
    "                feature_view=feature_view\n",
    "            )\n",
    "            \n",
    "            # Upload the model and artifacts\n",
    "            model_api.save(model_dir)\n",
    "            \n",
    "            # Clean up local model directory\n",
    "            import shutil\n",
    "            shutil.rmtree(model_dir, ignore_errors=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"FAILED for item {item}, location {loc}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
