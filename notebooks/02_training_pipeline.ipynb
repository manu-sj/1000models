{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecasting Model Training Pipeline\n",
    "\n",
    "This notebook trains demand forecasting models for each item-location combination using the feature store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lex/miniforge3/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hopsworks\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "Set the parameters for the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure training parameters\n",
    "project_name = 'many_models'\n",
    "feature_group_name = 'demand_features'\n",
    "version = 1  # Version can be incremented automatically \n",
    "model_name = 'demand_forecaster'\n",
    "# model_version = 1  # Let Hopsworks handle versioning automatically\n",
    "test_size = 0.2\n",
    "location_id = None  # Set to specific location ID to filter for a single location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks\n",
    "\n",
    "Establish connection to the Hopsworks Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Hopsworks\n",
      "2025-05-09 10:21:38,202 INFO: Initializing external client\n",
      "2025-05-09 10:21:38,203 INFO: Base URL: https://demo.hops.works:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 10:21:39,219 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://demo.hops.works:443/p/14455\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to Hopsworks\")\n",
    "# Connect to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    host=os.getenv(\"HOST\"),\n",
    "    port=os.getenv(\"PORT\"),\n",
    "    api_key_value=os.getenv(\"HOPSWORKS_API_KEY\"),\n",
    "    project=project_name or os.getenv(\"PROJECT\")\n",
    ")\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Feature Group\n",
    "\n",
    "Get the feature group containing the demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Feature Group: demand_features\n",
      "Feature Group Investigation\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.93s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_id</th>\n",
       "      <th>loc_id</th>\n",
       "      <th>time_bucket</th>\n",
       "      <th>repetitive_demand_quantity</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9032806</td>\n",
       "      <td>3</td>\n",
       "      <td>202404</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2025-05-09 10:05:45.219201+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8636975</td>\n",
       "      <td>3</td>\n",
       "      <td>202111</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2025-05-09 10:05:45.219201+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9052071</td>\n",
       "      <td>3</td>\n",
       "      <td>202406</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2025-05-09 10:05:45.219201+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9036438</td>\n",
       "      <td>3</td>\n",
       "      <td>202203</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>2025-05-09 10:05:45.219201+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8413714</td>\n",
       "      <td>3</td>\n",
       "      <td>202312</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2025-05-09 10:05:45.219201+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sp_id  loc_id  time_bucket  repetitive_demand_quantity  \\\n",
       "0  9032806       3       202404                        21.0   \n",
       "1  8636975       3       202111                       339.0   \n",
       "2  9052071       3       202406                        65.0   \n",
       "3  9036438       3       202203                      1284.0   \n",
       "4  8413714       3       202312                        21.0   \n",
       "\n",
       "                          datetime  \n",
       "0 2025-05-09 10:05:45.219201+00:00  \n",
       "1 2025-05-09 10:05:45.219201+00:00  \n",
       "2 2025-05-09 10:05:45.219201+00:00  \n",
       "3 2025-05-09 10:05:45.219201+00:00  \n",
       "4 2025-05-09 10:05:45.219201+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Retrieving Feature Group: {feature_group_name}\")\n",
    "demand_fg = fs.get_feature_group(\n",
    "    name=feature_group_name,\n",
    "#    version=1,  # Using fixed version if needed\n",
    ")\n",
    "\n",
    "print(\"Feature Group Investigation\")\n",
    "demand_fg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Query\n",
    "\n",
    "Select features and prepare the query for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Selection\")\n",
    "# Define query with proper feature selection\n",
    "query = demand_fg.select_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Transformation Functions\n",
    "\n",
    "Define transformation functions for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up transformation functions\n",
      "Applying label encoding to location ID\n",
      "Created transformation function for loc_id using label_encoder\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up transformation functions\")\n",
    "# Import the built-in transformations\n",
    "from hopsworks.hsfs.builtin_transformations import label_encoder\n",
    "\n",
    "print(\"Applying label encoding to location ID\")\n",
    "transformation_functions = [label_encoder(\"loc_id\")]\n",
    "\n",
    "print(\"Created transformation function for loc_id using label_encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature View\n",
    "\n",
    "Create a feature view for the demand data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting or creating feature view: demand_features_view\n",
      "Feature view created successfully, explore it at \n",
      "https://demo.hops.works:443/p/14455/fs/13379/fv/demand_features_view/version/1\n",
      "Successfully got or created feature view: demand_features_view\n"
     ]
    }
   ],
   "source": [
    "print(f\"Getting or creating feature view: {feature_group_name}_view\")\n",
    "\n",
    "# Use get_or_create_feature_view method\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=f\"{feature_group_name}_view\",\n",
    "    version=1,  \n",
    "    description=\"Feature view for demand forecasting\",\n",
    "    labels=[\"repetitive_demand_quantity\"],\n",
    "    query=query,\n",
    "    transformation_functions=transformation_functions\n",
    ")\n",
    "\n",
    "print(f\"Successfully got or created feature view: {feature_group_name}_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Training Scope\n",
    "\n",
    "Determine the number of models to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.61s) \n",
      "Training 200 models (items: 200 × locations: 1)\n",
      "\n",
      "Data Overview:\n",
      "Unique items: 200\n",
      "Unique locations: 1\n"
     ]
    }
   ],
   "source": [
    "# Get model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Get unique items and locations for training\n",
    "# Read the data once and reuse it\n",
    "df = query.read()\n",
    "items = df['sp_id'].unique()  # Get unique items\n",
    "locations = df['loc_id'].unique() if location_id is None else [location_id]\n",
    "\n",
    "# Calculate total number of models\n",
    "total_models = len(items) * len(locations)\n",
    "\n",
    "print(f\"Training {total_models} models (items: {len(items)} × locations: {len(locations)})\")\n",
    "\n",
    "print(f\"\\nData Overview:\")\n",
    "print(f\"Unique items: {len(items)}\")\n",
    "print(f\"Unique locations: {len(locations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Loop\n",
    "\n",
    "Train models for each item-location combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store metrics for all models\n",
    "all_model_metrics = {}\n",
    "\n",
    "# Counter for progress tracking\n",
    "model_counter = 0\n",
    "\n",
    "# Loop through each item-location combination\n",
    "for item in items:\n",
    "    for loc in locations:\n",
    "        model_counter += 1\n",
    "        \n",
    "        # Display progress periodically\n",
    "        if model_counter % 5 == 0 or model_counter == 1:\n",
    "            print(f\"Training model {model_counter}/{total_models} (Item: {item}, Location: {loc})\")\n",
    "        \n",
    "        try:\n",
    "            # Create a filter for this item-location combination\n",
    "            from hsfs.constructor.filter import Filter\n",
    "            \n",
    "            # Create filter using feature group \n",
    "            filter_cond = (demand_fg.sp_id == item) and (demand_fg.loc_id == loc)\n",
    "            \n",
    "            # Apply train_test_split with extra_filter\n",
    "            X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "                test_size=test_size,\n",
    "                extra_filter=filter_cond,\n",
    "                )\n",
    "                        \n",
    "            # Skip if we don't have enough data for this combination\n",
    "            if len(X_train) < 10 or len(X_test) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Remove ID columns\n",
    "            X_train = X_train.drop(['sp_id', 'loc_id', 'datetime'], axis=1, errors='ignore')\n",
    "            X_test = X_test.drop(['sp_id', 'loc_id', 'datetime'], axis=1, errors='ignore')\n",
    "            \n",
    "            # Model name for this item-location\n",
    "            model_prefix = f\"{model_name}_item{item}_loc{loc}\"\n",
    "            \n",
    "            # Train RandomForest\n",
    "            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Train XGBoost\n",
    "            xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate models\n",
    "            models = {\n",
    "                \"RandomForest\": rf_model,\n",
    "                \"XGBoost\": xgb_model\n",
    "            }\n",
    "            \n",
    "            best_model = None\n",
    "            best_rmse = float('inf')\n",
    "            best_metrics = {}\n",
    "            \n",
    "            for model_type, model in models.items():\n",
    "                # Make predictions\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "                \n",
    "                metrics = {\n",
    "                    \"mae\": mae,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"r2\": r2\n",
    "                }\n",
    "                \n",
    "                if model_counter % 5 == 0 or model_counter == 1:\n",
    "                    print(f\"  {model_type}: RMSE: {rmse:.2f}\")\n",
    "                \n",
    "                # Track best model\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse = rmse\n",
    "                    best_model = model\n",
    "                    best_model_type = model_type\n",
    "                    best_metrics = metrics\n",
    "            \n",
    "            # Store metrics for this item-location combination\n",
    "            all_model_metrics[f\"item_{item}_loc_{loc}\"] = {\n",
    "                \"model_type\": best_model_type,\n",
    "                \"metrics\": best_metrics\n",
    "            }\n",
    "            \n",
    "            # Create model directory\n",
    "            model_dir = model_prefix\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            \n",
    "            # Save model\n",
    "            if best_model_type == \"RandomForest\":\n",
    "                joblib.dump(best_model, os.path.join(model_dir, \"model.joblib\"))\n",
    "            else:  # XGBoost\n",
    "                best_model.save_model(os.path.join(model_dir, \"model.json\"))\n",
    "            \n",
    "            # Register model in Hopsworks\n",
    "            model_api = mr.python.create_model(\n",
    "                name=model_prefix,\n",
    "                metrics=best_metrics,\n",
    "                description=f\"Demand forecaster for item {item}, location {loc}\",\n",
    "                input_example=X_train.iloc[0].to_dict() if not X_train.empty else None,\n",
    "                feature_view=feature_view\n",
    "            )\n",
    "            \n",
    "            # Upload the model and artifacts\n",
    "            model_api.save(model_dir)\n",
    "            \n",
    "            # Clean up local model directory\n",
    "            import shutil\n",
    "            shutil.rmtree(model_dir, ignore_errors=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"FAILED for item {item}, location {loc}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
