{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecasting Inference Pipeline\n",
    "\n",
    "This notebook demonstrates how to make demand predictions for specific item-location combinations using trained models from the model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Parameters\n",
    "\n",
    "Set the parameters for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure inference parameters\n",
    "project_name = 'models1000'\n",
    "model_name = 'demand_forecaster'\n",
    "item_id = 9684698  # Item ID to predict demand for\n",
    "location_id = 3     # Location ID\n",
    "time_bucket = 202101  # Time period (YYYYMM format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks\n",
    "\n",
    "Establish connection to the Hopsworks model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting to Hopsworks\")\n",
    "# Connect to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    host=os.getenv(\"HOST\"),\n",
    "    port=os.getenv(\"PORT\"),\n",
    "    api_key_value=os.getenv(\"HOPSWORKS_API_KEY\"),\n",
    "    project=project_name or os.getenv(\"PROJECT\")\n",
    ")\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Best Model\n",
    "\n",
    "Find the best model for the specified item-location combination based on RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format model name for the specific item-location combination\n",
    "model_prefix = f\"{model_name}_item{item_id}_loc{location_id}\"\n",
    "print(f\"Looking for model: {model_prefix}\")\n",
    "\n",
    "# Get the best model based on RMSE (lower is better)\n",
    "model_instance = mr.get_best_model(name=model_prefix, \n",
    "                                   evaluation_metric=\"rmse\", \n",
    "                                   sort_metrics_by=\"min\")\n",
    "print(f\"Found best model for {model_prefix} (version {model_instance.version})\")\n",
    "\n",
    "# Get model metrics\n",
    "metrics = model_instance.get_metrics()\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Download the model\n",
    "model_dir = model_instance.download()\n",
    "print(f\"Model downloaded to {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Inference Data\n",
    "\n",
    "Create a dataframe with the time period for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inference data for the specific time bucket\n",
    "inference_data = pd.DataFrame([{\n",
    "    'time_bucket': time_bucket\n",
    "}])\n",
    "\n",
    "display(inference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Prediction\n",
    "\n",
    "Load the model and make a demand prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (supports both RandomForest and XGBoost formats)\n",
    "if os.path.exists(os.path.join(model_dir, \"model.joblib\")):\n",
    "    print(\"Loading RandomForest model\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "else:\n",
    "    print(\"Loading XGBoost model\")\n",
    "    import xgboost as xgb\n",
    "    model = xgb.XGBRegressor()\n",
    "    model.load_model(os.path.join(model_dir, \"model.json\"))\n",
    "\n",
    "# Make prediction\n",
    "prediction = float(model.predict(inference_data)[0])\n",
    "prediction = max(0, prediction)  # Ensure non-negative\n",
    "\n",
    "# Display the result\n",
    "print(f\"\\nDemand Prediction Results:\")\n",
    "print(f\"Item: {item_id}\")\n",
    "print(f\"Location: {location_id}\")\n",
    "print(f\"Time Period: {str(time_bucket)[:4]}-{str(time_bucket)[4:]}\")\n",
    "print(f\"Predicted Demand: {prediction:.2f} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Prediction\n",
    "\n",
    "Create a simple visualization of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple bar chart of the predicted demand\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=['Predicted Demand'], y=[prediction], palette='viridis')\n",
    "plt.title(f'Predicted Demand for Item {item_id} at Location {location_id}', fontsize=14)\n",
    "plt.ylabel('Demand Units', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting for Multiple Time Periods\n",
    "\n",
    "Let's predict demand across multiple time periods to see trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of time periods to predict for\n",
    "time_periods = [202101, 202102, 202103, 202104, 202105, 202106]\n",
    "predictions = []\n",
    "\n",
    "for period in time_periods:\n",
    "    # Create inference data for this time period\n",
    "    period_data = pd.DataFrame([{\n",
    "        'time_bucket': period\n",
    "    }])\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = float(model.predict(period_data)[0])\n",
    "    pred = max(0, pred)  # Ensure non-negative\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Create a time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_periods, predictions, marker='o', linestyle='-', linewidth=2, markersize=10)\n",
    "plt.title(f'Demand Forecast Trend for Item {item_id} at Location {location_id}', fontsize=14)\n",
    "plt.xlabel('Time Period (YYYYMM)', fontsize=12)\n",
    "plt.ylabel('Predicted Demand', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(time_periods, [f\"{str(p)[:4]}-{str(p)[4:]}\" for p in time_periods], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction Function\n",
    "\n",
    "A reusable function for batch predictions across multiple items or locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(items, locations, time_period):\n",
    "    \"\"\"Predict demand for multiple item-location combinations\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for item in items:\n",
    "        for loc in locations:\n",
    "            # Get model name for this item-location\n",
    "            model_prefix = f\"{model_name}_item{item}_loc{loc}\"\n",
    "            \n",
    "            try:\n",
    "                # Get the best model\n",
    "                model_instance = mr.get_best_model(name=model_prefix, \n",
    "                                               evaluation_metric=\"rmse\", \n",
    "                                               sort_metrics_by=\"min\")\n",
    "                \n",
    "                # Download model\n",
    "                model_dir = model_instance.download()\n",
    "                \n",
    "                # Load the model\n",
    "                if os.path.exists(os.path.join(model_dir, \"model.joblib\")):\n",
    "                    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "                else:\n",
    "                    import xgboost as xgb\n",
    "                    model = xgb.XGBRegressor()\n",
    "                    model.load_model(os.path.join(model_dir, \"model.json\"))\n",
    "                \n",
    "                # Create inference data - only need time_bucket\n",
    "                inference_data = pd.DataFrame([{'time_bucket': time_period}])\n",
    "                \n",
    "                # Make prediction\n",
    "                prediction = float(model.predict(inference_data)[0])\n",
    "                prediction = max(0, prediction)  # Ensure non-negative\n",
    "                \n",
    "                # Store result\n",
    "                results.append({\n",
    "                    'item_id': item,\n",
    "                    'location_id': loc,\n",
    "                    'time_period': time_period,\n",
    "                    'predicted_demand': prediction,\n",
    "                    'rmse': model_instance.get_metrics().get('rmse', None),\n",
    "                    'model_type': model_instance.model_schema.get('model_class', None)\n",
    "                })\n",
    "                \n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example batch prediction\n",
    "items_to_predict = [9684698, 8606896]\n",
    "locations_to_predict = [3]\n",
    "time_period = 202101\n",
    "\n",
    "# Run batch prediction\n",
    "batch_results = batch_predict(items_to_predict, locations_to_predict, time_period)\n",
    "\n",
    "# Display results\n",
    "display(batch_results)\n",
    "\n",
    "# Visualize batch results\n",
    "if not batch_results.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x='item_id', y='predicted_demand', hue='location_id', data=batch_results)\n",
    "    plt.title(f'Predicted Demand by Item and Location for Period {time_period}', fontsize=14)\n",
    "    plt.xlabel('Item ID', fontsize=12)\n",
    "    plt.ylabel('Predicted Demand', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Add RMSE values as annotations\n",
    "    for i, row in enumerate(batch_results.itertuples()):\n",
    "        if hasattr(row, 'rmse') and row.rmse is not None:\n",
    "            ax.text(i, row.predicted_demand + 0.1, f'RMSE: {row.rmse:.2f}', \n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
